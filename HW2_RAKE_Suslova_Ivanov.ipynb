{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №2. RAKE\n",
    "## Выполнили: Суслова Дарья, Иванов Вячеслав\n",
    "\n",
    "Для анализа был выбран текст об истории картины Леонардо да Винчи \"Мона Лиза\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ключевые слова (Даша):\n",
    "- Lisa del Giocondo\n",
    "- Mona Lisa\n",
    "- Lisa\n",
    "- portrait\n",
    "- Leonardo da Vinci\n",
    "- most famous painting\n",
    "- work of art\n",
    "- icon\n",
    "- model\n",
    "- portray\n",
    "- Leonardo\n",
    "- Louvre\n",
    "- painting\n",
    "- France\n",
    "- La Gioconda\n",
    "\n",
    "Ключевые слова (Слава):\n",
    "- Mona Lisa\n",
    "- Italian noblewoman \n",
    "- Italy \n",
    "- portrait \n",
    "- Leonardo da Vinci \n",
    "- most famous painting \n",
    "- woman \n",
    "- globally recognized icon \n",
    "- object of commercialization \n",
    "- model\n",
    "- art \n",
    "- fame\n",
    "- La Gioconda  \n",
    "- painting \n",
    "- possession\n",
    "\n",
    "Процент совпадения: 53,3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Золотой стандарт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lisa del Giocondo\n",
    "* Mona Lisa \n",
    "* Italy\n",
    "* portrait \n",
    "* Leonardo da Vinci \n",
    "* most famous painting  \n",
    "* woman\n",
    "* globally recognized icon\n",
    "* model\n",
    "* art \n",
    "* fame\n",
    "* La Gioconda \n",
    "* Leonardo\n",
    "* Louvre\n",
    "* painting \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import six\n",
    "\n",
    "from nlp_rake import rake\n",
    "import operator\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE ONE - SIMPLE\n",
    "stoppath = 'data/stoplists/SmartStoplist.txt'\n",
    "\n",
    "# 1. initialize RAKE by providing a path to a stopwords file\n",
    "rake_object = rake.Rake(stoppath, 5, 3, 2)\n",
    "\n",
    "# 2. run on RAKE on a given text\n",
    "sample_file = io.open(\"mona.txt\", 'r')\n",
    "text = sample_file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: lisa del giocondo \n",
      " Score: 8.266666666666666\n",
      "Keyword: mona lisa \n",
      " Score: 4.377777777777778\n",
      "Keyword: leonardo \n",
      " Score: 1.6666666666666667\n",
      "Keyword: francesco \n",
      " Score: 1.6666666666666667\n",
      "Keyword: people \n",
      " Score: 1.6666666666666667\n",
      "Keyword: portrait \n",
      " Score: 1.4285714285714286\n",
      "Keyword: paintings \n",
      " Score: 1.3333333333333333\n",
      "Keyword: painting \n",
      " Score: 1.2\n",
      "Keyword: florence \n",
      " Score: 1.0\n",
      "Keyword: husband \n",
      " Score: 1.0\n",
      "Keyword: married \n",
      " Score: 1.0\n",
      "Keyword: woman \n",
      " Score: 1.0\n",
      "Keyword: scholars \n",
      " Score: 1.0\n",
      "Keyword: louvre \n",
      " Score: 1.0\n",
      "Keyword: france \n",
      " Score: 1.0\n",
      "Keyword: happy \n",
      " Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "keywords = rake_object.run(text)\n",
    "\n",
    "for k in keywords:\n",
    "    print (\"Keyword:\", k[0], \"\\n\", \"Score:\", k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Совпадение с ЗС 46,6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ результатов\n",
    "По нашему мнению, система неверно выделила следующие слова: 'people', 'paintings', 'scholars' и 'happy'. \n",
    "\n",
    "Слова 'people', 'scholars'  и 'happy' в данном тексте употребляются в разделе с дополнительной информацией и не относятся к ключевым, а слово 'paintings' уже имеется в выдаче в форме единственного числа. Наоборот, система хорошо выделила слова 'francesco', 'florence', 'husband', 'married', которые не были выделены нами. Они являются значимыми в описании истории картины. \n",
    "\n",
    "С другой стороны, RAKE не распознал в качестве ключевых такие слова и выражения, как 'globally recognized icon', 'model', 'art', 'fame', 'La Gioconda', 'Italy', 'most famous painting', которые в первую очередь характеризуют \"Мону Лизу\" Леонардо да Винчи. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытка улучшить Rake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализировав результаты, мы пришли к выводу, что улучшение алгоритма должно происходить на этапе препроцессинга, где происходит деление на слова. На этапе препроцессинга был добавлен токенизатор и лемматизатор из NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #улучшение препроцессинга\n",
    "from nltk import word_tokenize #токенизирование\n",
    "from nltk.stem.wordnet import WordNetLemmatizer #лемматизация\n",
    "lmtzr = WordNetLemmatizer() #лемматизация\n",
    "\n",
    "#улучшение препроцессинга\n",
    "def separate_words(text, min_word_return_size):\n",
    "    \"\"\"\n",
    "    Utility function to return a list of all words that are have a length greater than a specified number of characters.\n",
    "    @param text The text that must be split in to words.\n",
    "    @param min_word_return_size The minimum no of characters a word must have to be included.\n",
    "    \"\"\"\n",
    "    splitter = re.compile('[^a-zA-Z0-9_\\\\+\\\\-/]')\n",
    "    words = []\n",
    "    tokens = word_tokenize(text) #токенизирование\n",
    "    lemmas = [lmtzr.lemmatize(t) for t in tokens] #лемматизация\n",
    "\n",
    "    for current_word in lemmas: #улучшение препроцессинга\n",
    "        # leave numbers in phrase, but don't count as words, since they tend to invalidate scores of their phrases\n",
    "        if len(current_word) > min_word_return_size and current_word != '' and not is_number(current_word):\n",
    "            words.append(current_word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, по результату ниже можно заметить, что предпологаемые нами исправления не помогли в итоге улучшить выдачу, хотя ожидалось, что результаты будут более чистые за счет лемматизации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: lisa del giocondo \n",
      " Score: 8.266666666666666\n",
      "Keyword: mona lisa \n",
      " Score: 4.377777777777778\n",
      "Keyword: leonardo \n",
      " Score: 1.6666666666666667\n",
      "Keyword: francesco \n",
      " Score: 1.6666666666666667\n",
      "Keyword: people \n",
      " Score: 1.6666666666666667\n",
      "Keyword: portrait \n",
      " Score: 1.4285714285714286\n",
      "Keyword: painting \n",
      " Score: 1.25\n",
      "Keyword: paintings \n",
      " Score: 1.25\n",
      "Keyword: florence \n",
      " Score: 1.0\n",
      "Keyword: husband \n",
      " Score: 1.0\n",
      "Keyword: married \n",
      " Score: 1.0\n",
      "Keyword: woman \n",
      " Score: 1.0\n",
      "Keyword: scholars \n",
      " Score: 1.0\n",
      "Keyword: louvre \n",
      " Score: 1.0\n",
      "Keyword: france \n",
      " Score: 1.0\n",
      "Keyword: happy \n",
      " Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#результат\n",
    "\n",
    "keywords = rake_object.run(text)\n",
    "\n",
    "for k in keywords:\n",
    "    print (\"Keyword:\", k[0], \"\\n\", \"Score:\", k[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rake на русском тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE ONE - SIMPLE\n",
    "stoppath = 'RussianStoplist.txt'\n",
    "\n",
    "# 1. initialize RAKE by providing a path to a stopwords file\n",
    "rake_object = rake.Rake(stoppath, 5, 3, 2)\n",
    "\n",
    "# 2. run on RAKE on a given text\n",
    "sample_file = io.open(\"russian_test.txt\", 'r', encoding='UTF-8')\n",
    "textR = sample_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "keywordsR = rake_object.run(textR)\n",
    "print(keywordsR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно видеть из кода выше, то RAKE для русского не работает. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
